{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TTywYgc6YEV"
      },
      "outputs": [],
      "source": [
        "!pip install webrtcvad\n",
        "!pip install spectralcluster\n",
        "!pip install ffmpeg-python\n",
        "!pip install Speechrecognition\n",
        "!pip install pydub\n",
        "!pip install azure-cognitiveservices-speech"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "def mp3_to_wav(audio_file_path):\n",
        "    sound = AudioSegment.from_mp3(audio_file_path)\n",
        "    audio_file_path = audio_file_path.split('.')[0] + '.wav'\n",
        "    sound.export(audio_file_path, format=\"wav\")\n",
        "    return audio_file_path\n",
        "\n",
        "audio_file_path = mp3_to_wav('/content/sample1audio.wav')\n",
        "print(audio_file_path)"
      ],
      "metadata": {
        "id": "Sfve2e606aYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/resemble-ai/Resemblyzer.git\n",
        "%cd Resemblyzer"
      ],
      "metadata": {
        "id": "DGVGNJHs6a6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install webrtcvad\n",
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from pathlib import Path\n",
        "\n",
        "#give the file path to your audio file\n",
        "audio_file_path = '/content/sample1audio.wav'\n",
        "wav_fpath = Path(audio_file_path)\n",
        "\n",
        "wav = preprocess_wav(wav_fpath)\n",
        "encoder = VoiceEncoder(\"cpu\")\n",
        "_, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16)\n",
        "print(cont_embeds.shape)"
      ],
      "metadata": {
        "id": "iD6rRShg6clz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spectralcluster import SpectralClusterer\n",
        "from spectralcluster import RefinementOptions\n",
        "from spectralcluster import ThresholdType\n",
        "from spectralcluster import ICASSP2018_REFINEMENT_SEQUENCE\n",
        "\n",
        "clusterer = SpectralClusterer(\n",
        "    min_clusters=2,\n",
        "    max_clusters=100,\n",
        ")\n",
        "refinement_options = RefinementOptions(\n",
        "    gaussian_blur_sigma=1,\n",
        "    p_percentile=0.90)\n",
        "labels = clusterer.predict(cont_embeds)"
      ],
      "metadata": {
        "id": "Cb2xIxqr6gui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_labelling(labels,wav_splits):\n",
        "    from resemblyzer import sampling_rate\n",
        "    times = [((s.start + s.stop) / 2) / sampling_rate for s in wav_splits]\n",
        "    labelling = []\n",
        "    start_time = 0\n",
        "    \n",
        "    for i,time in enumerate(times):\n",
        "        if i>0 and labels[i]!=labels[i-1]:\n",
        "            temp = [str(labels[i-1]),start_time,time]\n",
        "            labelling.append(tuple(temp))\n",
        "            start_time = time\n",
        "        if i==len(times)-1:\n",
        "            temp = [str(labels[i]),start_time,time]\n",
        "            labelling.append(tuple(temp))\n",
        "    return labelling\n",
        "  \n",
        "labelling = create_labelling(labels,wav_splits)"
      ],
      "metadata": {
        "id": "RSYghpPh6jVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labelling"
      ],
      "metadata": {
        "id": "MHcZQfoN6lP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "id": "W9cE7DQ06mqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "import speech_recognition as sr\n",
        "import time\n",
        "import os\n",
        "a=0\n",
        "r = sr.Recognizer()\n",
        "for label in labelling:\n",
        "  #print('1')\n",
        "  a=a+1\n",
        "  speaker=label[0]\n",
        "  start=label[1]\n",
        "  end=label[2]\n",
        "  audio_input = ffmpeg.input('/content/Driving-English-Conversation-Sample.wav')\n",
        "  #print(start)\n",
        "  #print(end)\n",
        "  audio_cut = audio_input.audio.filter('atrim', start=start,end=end)\n",
        "  audio_output = ffmpeg.output(audio_cut, f'{a}out.wav')\n",
        "  #print('2')\n",
        "  try:\n",
        "    #print('3')\n",
        "    ffmpeg.run(audio_output)\n",
        "  except:\n",
        "    #print('4')\n",
        "    pass\n",
        "  #time.sleep()\n",
        "  with sr.AudioFile(f'{a}out.wav') as source:\n",
        "    #print('5')\n",
        "    audio_text = r.listen(source)\n",
        "# recoginize_() method will throw a request error if the API is unreachable, hence using exception handling\n",
        "    try:\n",
        "      #print('6')\n",
        "        # using google speech recognition\n",
        "      text = r.recognize_google(audio_text)\n",
        "      print('Converting audio transcripts into text ...')\n",
        "      #print('7')\n",
        "      print(f'{speaker} : {text}')\n",
        "    except:\n",
        "      #print('8')\n",
        "      print('Sorry.. run again...')\n",
        "    time.sleep(1)\n",
        "    \n",
        "  os.remove(f'{a}out.wav')\n"
      ],
      "metadata": {
        "id": "SJiQa2jE6ogh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "import azure.cognitiveservices.speech as speechsdk\n",
        "import speech_recognition as sr\n",
        "import time\n",
        "import os\n",
        "a=0\n",
        "speech_key, service_region = \"speech_key\", \"service_region\"\n",
        "speech_config=speechsdk.SpeechConfig(subscription=speech_key, region=service_region)\n",
        "\n",
        "# Creates an audio configuration that points to an audio file.\n",
        "# Replace with your own audio filename.\n",
        "audio_filename = \"/content/sample1audio.wav\"\n",
        "audio_input = speechsdk.audio.AudioConfig(filename=audio_filename)\n",
        "\n",
        "# Creates a recognizer with the given settings\n",
        "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_input)\n",
        "\n",
        "#print(\"Recognizing first result...\")\n",
        "\n",
        "for label in labelling:\n",
        "  #print('1')\n",
        "  a=a+1\n",
        "  speaker=label[0]\n",
        "  start=label[1]\n",
        "  end=label[2]\n",
        "  audio_input = ffmpeg.input('/content/sample1audio.wav')\n",
        "  #print(start)\n",
        "  #print(end)\n",
        "  audio_cut = audio_input.audio.filter('atrim', start=start,end=end)\n",
        "  audio_output = ffmpeg.output(audio_cut, f'{a}out.wav')\n",
        "  #print('2')\n",
        "  try:\n",
        "    #print('3')\n",
        "    ffmpeg.run(audio_output)\n",
        "  except:\n",
        "    #print('4')\n",
        "    pass\n",
        "  #time.sleep()\n",
        "  with sr.AudioFile(f'{a}out.wav') as source:\n",
        "    result = speech_recognizer.recognize_once()\n",
        "\n",
        "    # Checks result.\n",
        "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
        "        #print(\"Recognized by Azure: {}\".format(result.text))\n",
        "        #print(speaker)\n",
        "        #'''\n",
        "        if speaker=='0':\n",
        "          print(f\"Agent: {result.text}\")\n",
        "        else:\n",
        "          print(f\"Customer: {result.text}\")\n",
        "          #'''\n",
        "        #print(f\"{speaker}: {result.text}\")\n",
        "    elif result.reason == speechsdk.ResultReason.NoMatch:\n",
        "        print(\"No speech could be recognized: {}\".format(result.no_match_details))\n",
        "        #pass\n",
        "    elif result.reason == speechsdk.ResultReason.Canceled:\n",
        "        cancellation_details = result.cancellation_details\n",
        "        #print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
        "        pass\n",
        "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
        "\n",
        "\n",
        "  os.remove(f'{a}out.wav')"
      ],
      "metadata": {
        "id": "7fAj0DSd6r03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}